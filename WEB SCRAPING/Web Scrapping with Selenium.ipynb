{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba67fe38",
   "metadata": {},
   "source": [
    "# Web Scrapping with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58cffa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479801dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4680b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb48278",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d53241d9",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6607cf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Analyst II</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business and Data Analyst</td>\n",
       "      <td>CAREERDOST ENTERPRISE</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Capco</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>G S E-COMMERCE PVT LTD</td>\n",
       "      <td>Bangalore/Bengaluru(Jayanagar)</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Python / SQL</td>\n",
       "      <td>Myntra</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reference Data Analyst</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst with SAP ABAP &amp; BW - C...</td>\n",
       "      <td>MILLION MINDS INFOTECH PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAS Analyst / data Analyst / Business analyst ...</td>\n",
       "      <td>Leading US MNC into analytics</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst 2-1</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                 Sr Data Analyst II   \n",
       "1                          Business and Data Analyst   \n",
       "2                                Senior Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                        Data Analyst - Python / SQL   \n",
       "5                             Reference Data Analyst   \n",
       "6  Hiring For Data Analyst with SAP ABAP & BW - C...   \n",
       "7  SAS Analyst / data Analyst / Business analyst ...   \n",
       "8                                   Data Analyst 2-1   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                  Company  \\\n",
       "0                              IHS Markit   \n",
       "1                   CAREERDOST ENTERPRISE   \n",
       "2                                   Capco   \n",
       "3                  G S E-COMMERCE PVT LTD   \n",
       "4                                  Myntra   \n",
       "5                           Deutsche Bank   \n",
       "6  MILLION MINDS INFOTECH PRIVATE LIMITED   \n",
       "7           Leading US MNC into analytics   \n",
       "8                                  PayPal   \n",
       "9                                  PayPal   \n",
       "\n",
       "                                            Location Experience_Required  \n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru             3-6 Yrs  \n",
       "1                                Bangalore/Bengaluru             0-5 Yrs  \n",
       "2  Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...            7-12 Yrs  \n",
       "3                     Bangalore/Bengaluru(Jayanagar)             4-7 Yrs  \n",
       "4                                Bangalore/Bengaluru             1-4 Yrs  \n",
       "5                                Bangalore/Bengaluru             2-5 Yrs  \n",
       "6                                Bangalore/Bengaluru            7-10 Yrs  \n",
       "7  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...             2-7 Yrs  \n",
       "8                                Bangalore/Bengaluru             5-8 Yrs  \n",
       "9                                Bangalore/Bengaluru             1-3 Yrs  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening a naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "# finding elements for job search bar\n",
    "search_field_designation=driver.find_element_by_class_name('suggestor-input')\n",
    "search_field_designation.send_keys('Data Analyst')\n",
    "\n",
    "#finding element for location search\n",
    "\n",
    "search_field_location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_field_location.send_keys('Bangalore')\n",
    "\n",
    "#finding search button and click\n",
    "search_button=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(5) # Sleep for 5 seconds to open a page\n",
    "\n",
    "#extracting all the tags having job title,company names,location adn experience\n",
    "job_title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "#len(job_title_tags)\n",
    "#len(company_tags)\n",
    "#len(location_tags)\n",
    "#len(experience_tags)\n",
    "\n",
    "#creating empty list to capture reults\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "# Fetching data from tags and appending in list elements\n",
    "for i in range(0,10):\n",
    "    job_title.append(job_title_tags[i].text)\n",
    "    company_name.append(company_tags[i].text)\n",
    "    experience_required.append(experience_tags[i].text)\n",
    "    \n",
    "# different loop becuase we are also getting \"(WFH during Covid)\" string in location\n",
    "for j in location_tags:\n",
    "    if j.text!='(WFH during Covid)':\n",
    "        job_location.append(j.text)\n",
    "    if len(job_location)==10:\n",
    "        break\n",
    "\n",
    "#Create data frame\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_title\n",
    "jobs['Company']=company_name\n",
    "jobs['Location']=job_location\n",
    "jobs['Experience_Required']=experience_required\n",
    "\n",
    "driver.close()\n",
    "\n",
    "jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73317a",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "144d2c21",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c03760ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cognitive/AI Senior Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead - Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Associate - Data Scientist</td>\n",
       "      <td>Affine</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rolls-Royce Data Labs : Data Scientist</td>\n",
       "      <td>Rolls Royce</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Job Opening with Wipro For Data Scientist - SAS</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Target</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist -Python+ML(5-7 years)</td>\n",
       "      <td>Knowledge Foundry Business Solutions Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title  \\\n",
       "0               Cognitive/AI Senior Data Scientist   \n",
       "1                            Lead - Data Scientist   \n",
       "2                Senior Associate - Data Scientist   \n",
       "3           Rolls-Royce Data Labs : Data Scientist   \n",
       "4                                   Data Scientist   \n",
       "5          Data Scientist: Artificial Intelligence   \n",
       "6  Job Opening with Wipro For Data Scientist - SAS   \n",
       "7                            Senior Data Scientist   \n",
       "8                                Sr Data Scientist   \n",
       "9      Senior Data Scientist -Python+ML(5-7 years)   \n",
       "\n",
       "                                          Company  \\\n",
       "0                                             IBM   \n",
       "1                               Applied Materials   \n",
       "2                                          Affine   \n",
       "3                                     Rolls Royce   \n",
       "4                               Applied Materials   \n",
       "5                                             IBM   \n",
       "6                                           Wipro   \n",
       "7                              Scienaptic Systems   \n",
       "8                                          Target   \n",
       "9  Knowledge Foundry Business Solutions Pvt. Ltd.   \n",
       "\n",
       "                                            Location  \n",
       "0                                Bangalore/Bengaluru  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2                                             Remote  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening a naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "# finding elements for job search bar\n",
    "search_field_designation=driver.find_element_by_class_name('suggestor-input')\n",
    "search_field_designation.send_keys('Data Scientist')\n",
    "\n",
    "#finding element for location search\n",
    "\n",
    "search_field_location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_field_location.send_keys('Bangalore')\n",
    "\n",
    "#finding search button and click\n",
    "search_button=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(5) # Sleep for 5 seconds to open a page\n",
    "\n",
    "#extracting all the tags having job title,company names,location adn experience\n",
    "job_title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "#len(job_title_tags)\n",
    "#len(company_tags)\n",
    "#len(location_tags)\n",
    "\n",
    "#creating empty list to capture reults\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "\n",
    "# Fetching data from tags and appending in list elements\n",
    "for i in range(0,10):\n",
    "    job_title.append(job_title_tags[i].text)\n",
    "    company_name.append(company_tags[i].text)\n",
    "    \n",
    "# different loop becuase we are also getting \"(WFH during Covid)\" string in location\n",
    "for j in location_tags:\n",
    "    if j.text!='(WFH during Covid)':\n",
    "        job_location.append(j.text)\n",
    "    if len(job_location)==10:\n",
    "        break\n",
    "\n",
    "#Create data frame\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_title\n",
    "jobs['Company']=company_name\n",
    "jobs['Location']=job_location\n",
    "\n",
    "driver.close()\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb3e15",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below: location and salary filter\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e689c1c7",
   "metadata": {},
   "source": [
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35470024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening a naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "# finding elements for job search bar\n",
    "search_field_designation=driver.find_element_by_class_name('suggestor-input')\n",
    "search_field_designation.send_keys('Data Scientist')\n",
    "\n",
    "\n",
    "#finding search button and click\n",
    "search_button=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(5) # Sleep for 5 seconds to open a page\n",
    "\n",
    "#finding location filter element to click \n",
    "filter_field_location=driver.find_element_by_xpath(\"//label[@for='chk-Delhi / NCR-cityTypeGid-']/i\")\n",
    "filter_field_location.click()\n",
    "\n",
    "#finding Salary filter element to click \n",
    "filter_field_salary=driver.find_element_by_xpath(\"//label[@for='chk-3-6 Lakhs-ctcFilter-']/i\")\n",
    "filter_field_salary.click()\n",
    "\n",
    "#extracting all the tags having job title,company names,location adn experience\n",
    "job_title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "\n",
    "#len(job_title_tags)\n",
    "#len(company_tags)\n",
    "#len(location_tags)\n",
    "#len(experience_tags)\n",
    "\n",
    "#creating empty list to capture reults\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "# Fetching data from tags and appending in list elements\n",
    "for i in range(0,10):\n",
    "    job_title.append(job_title_tags[i].text)\n",
    "    company_name.append(company_tags[i].text)\n",
    "    experience_required.append(experience_tags[i].text)\n",
    "    \n",
    "# different loop becuase we are also getting \"(WFH during Covid)\" string in location\n",
    "for j in location_tags:\n",
    "    if j.text!='(WFH during Covid)':\n",
    "        job_location.append(j.text)\n",
    "    if len(job_location)==10:\n",
    "        break\n",
    "\n",
    "#Create data frame\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_title\n",
    "jobs['Company']=company_name\n",
    "jobs['Location']=job_location\n",
    "jobs['Experience_Required']=experience_required\n",
    "\n",
    "driver.close()\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a500d3",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "078f5f7c",
   "metadata": {},
   "source": [
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "required data as usual.\n",
    "\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fcf91b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹630</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>27% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Polarized Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>41% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>27% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Mirrored, UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹3,349</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CRYSTAL CART</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹419</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Gradient Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹206</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Wrap-around Sunglasse...</td>\n",
       "      <td>₹721</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                       Product_Desc   Price  \\\n",
       "0     Singco India  Gradient, Toughened Glass Lens, UV Protection ...    ₹630   \n",
       "1   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹379   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹649   \n",
       "3               Mi           Polarized Aviator Sunglasses (Free Size)    ₹699   \n",
       "4         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹649   \n",
       "..             ...                                                ...     ...   \n",
       "95         Ray-Ban    Mirrored, UV Protection Aviator Sunglasses (58)  ₹3,349   \n",
       "96    CRYSTAL CART  UV Protection, Gradient Round Sunglasses (Free...    ₹419   \n",
       "97       ROYAL SON   UV Protection, Gradient Wayfarer Sunglasses (55)    ₹206   \n",
       "98        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹759   \n",
       "99       ROYAL SON  Polarized, UV Protection Wrap-around Sunglasse...    ₹721   \n",
       "\n",
       "   Discount  \n",
       "0   78% off  \n",
       "1   81% off  \n",
       "2   27% off  \n",
       "3   41% off  \n",
       "4   27% off  \n",
       "..      ...  \n",
       "95  40% off  \n",
       "96  79% off  \n",
       "97  79% off  \n",
       "98  15% off  \n",
       "99  63% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# finding elements for product search \n",
    "search_field_product=driver.find_element_by_class_name('_3704LK')\n",
    "search_field_product.send_keys('sunglasses')\n",
    "\n",
    "# finding popup close button\n",
    "search_button=driver.find_element_by_class_name('_2doB4z')\n",
    "search_button.click()\n",
    "\n",
    "#finding search click button\n",
    "search_button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_button.submit()\n",
    "\n",
    "time.sleep(5) # Sleep for 5 seconds to open a page\n",
    "\n",
    "# finding next button to go to next page\n",
    "search_next_button=driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "\n",
    "# list arrays to capture values\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#loop for next 3 pages to capture 100 records\n",
    "for i in range(0,3):\n",
    "    brand_tags=driver.find_elements_by_class_name(\"_2WkVRV\")\n",
    "    product_desc_tags=driver.find_elements_by_class_name(\"IRpwTa\")\n",
    "    price_tag=driver.find_elements_by_class_name(\"_30jeq3\")\n",
    "    discount_tag=driver.find_elements_by_class_name(\"_3Ay6Sb\")    \n",
    "    for j in range(0,40):\n",
    "        brand.append(brand_tags[j].text)\n",
    "        product_desc.append(product_desc_tags[j].text)\n",
    "        price.append(price_tag[j].text)\n",
    "        discount.append(discount_tag[j].text)\n",
    "        if len(brand)==100:\n",
    "            break\n",
    "    search_next_button.click()\n",
    "    time.sleep(5) \n",
    "\n",
    "\n",
    "#print('Brand Length: ',len(brand),'Desc Length:',len(product_desc),'Price Length:',len(price),'Discount Length:',len(discount))\n",
    "# creating data frame with values\n",
    "products = pd.DataFrame({})\n",
    "products['Brand']=brand\n",
    "products['Product_Desc']=product_desc\n",
    "products['Price']=price\n",
    "products['Discount']=discount\n",
    "\n",
    "driver.close() # closing chrome driver\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e719d",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bb5eb8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Amazing phone and on great deal I received wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>finally an iPhone with very nice battery backu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>I'm switching this phone to oppo reno 10x zoom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Simply Awesome\\n\\nI have upgraded from iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Damn this phone is a blast . Upgraded from and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating        review_summary  \\\n",
       "0       5             Brilliant   \n",
       "1       5        Simply awesome   \n",
       "2       5   Best in the market!   \n",
       "3       5      Perfect product!   \n",
       "4       5             Fabulous!   \n",
       "..    ...                   ...   \n",
       "95      5             Brilliant   \n",
       "96      5     Terrific purchase   \n",
       "97      4  Good quality product   \n",
       "98      5              Terrific   \n",
       "99      5   Best in the market!   \n",
       "\n",
       "                                          full_review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Amazing phone and on great deal I received wit...  \n",
       "96  finally an iPhone with very nice battery backu...  \n",
       "97  I'm switching this phone to oppo reno 10x zoom...  \n",
       "98  Simply Awesome\\n\\nI have upgraded from iPhone ...  \n",
       "99  Damn this phone is a blast . Upgraded from and...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "\n",
    "time.sleep(5) # Sleep for 5 seconds to open a page\n",
    "\n",
    "# finding all review elements for all reviews \n",
    "review_link=driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[10]/div/div/div[5]/div/a/div/span')\n",
    "review_link.click()\n",
    "\n",
    "\n",
    "time.sleep(5) # Sleep for 5 seconds to open a page\n",
    "\n",
    "# finding next button to go to next page\n",
    "next_button=driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]/span')\n",
    "\n",
    "# list arrays to capture values\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "#loop for next 10 pages to capture 100 records\n",
    "for i in range(0,10):\n",
    "    rating_tag=driver.find_elements_by_class_name(\"_1BLPMq\")\n",
    "    review_summary_tag=driver.find_elements_by_class_name(\"_2-N8zT\")\n",
    "    full_review_tag=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")   \n",
    "    for j in range(0,10):\n",
    "        rating.append(rating_tag[j].text)\n",
    "        review_summary.append(review_summary_tag[j].text)\n",
    "        full_review.append(full_review_tag[j].text)\n",
    "    if i<=0:\n",
    "        next_button.click()\n",
    "    else:\n",
    "        time.sleep(2) # putting time sleep for 2 seconds, sometimes page takes time to load\n",
    "        next_button_from_second_page=driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "        next_button_from_second_page.click()\n",
    "    time.sleep(5) \n",
    "\n",
    "\n",
    "# creating data frame with values\n",
    "reviews = pd.DataFrame({})\n",
    "reviews['rating']=rating\n",
    "reviews['review_summary']=review_summary\n",
    "reviews['full_review']=full_review\n",
    "\n",
    "driver.close() # closing chrome driver\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37381d0",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e57687e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹669</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹142</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KWIK FIT</td>\n",
       "      <td>Kwik FIT casual sneaker shoes and partywear sh...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corsac</td>\n",
       "      <td>STYLISH MENS BLACK SNEAKER Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,734</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-439 Sneakers For Men</td>\n",
       "      <td>₹799</td>\n",
       "      <td>5% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bacan</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹424</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lee Won</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹204</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Brand                                       Product_Desc  \\\n",
       "0          luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...   \n",
       "1              HIGHLANDER                                   Sneakers For Men   \n",
       "2                URBANBOX                          Sneakers Sneakers For Men   \n",
       "3                KWIK FIT  Kwik FIT casual sneaker shoes and partywear sh...   \n",
       "4                  corsac        STYLISH MENS BLACK SNEAKER Sneakers For Men   \n",
       "..                    ...                                                ...   \n",
       "95  HRX by Hrithik Roshan                                   Sneakers For Men   \n",
       "96                  SPARX                            SM-439 Sneakers For Men   \n",
       "97                  Bacan                                   Sneakers For Men   \n",
       "98         luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...   \n",
       "99                Lee Won                                   Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹449  65% off  \n",
       "1     ₹669  44% off  \n",
       "2     ₹142  85% off  \n",
       "3     ₹349  82% off  \n",
       "4     ₹449  70% off  \n",
       "..     ...      ...  \n",
       "95  ₹1,734  51% off  \n",
       "96    ₹799   5% off  \n",
       "97    ₹424  57% off  \n",
       "98    ₹449  65% off  \n",
       "99    ₹204  59% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "time.sleep(3) # Sleep for 3 seconds to open a page\n",
    "\n",
    "# finding elements for product search \n",
    "search_field_product=driver.find_element_by_class_name('_3704LK')\n",
    "search_field_product.send_keys('sneakers')\n",
    "\n",
    "# finding popup close button\n",
    "search_button=driver.find_element_by_class_name('_2doB4z')\n",
    "search_button.click()\n",
    "\n",
    "#finding search click button\n",
    "search_button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_button.submit()\n",
    "\n",
    "time.sleep(5) # Sleep for 5 seconds to open a page\n",
    "\n",
    "# finding next button to go to next page\n",
    "search_next_button=driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "\n",
    "# list arrays to capture values\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#loop for next 3 pages to capture 100 records\n",
    "for i in range(0,3):\n",
    "    brand_tags=driver.find_elements_by_class_name(\"_2WkVRV\")\n",
    "    product_desc_tags=driver.find_elements_by_class_name(\"IRpwTa\")\n",
    "    price_tag=driver.find_elements_by_class_name(\"_30jeq3\")\n",
    "    discount_tag=driver.find_elements_by_class_name(\"_3Ay6Sb\")    \n",
    "    for j in range(0,40):\n",
    "        brand.append(brand_tags[j].text)\n",
    "        product_desc.append(product_desc_tags[j].text)\n",
    "        price.append(price_tag[j].text)\n",
    "        discount.append(discount_tag[j].text)\n",
    "        if len(brand)==100:\n",
    "            break\n",
    "    search_next_button.click()\n",
    "    time.sleep(5) \n",
    "\n",
    "\n",
    "#print('Brand Length: ',len(brand),'Desc Length:',len(product_desc),'Price Length:',len(price),'Discount Length:',len(discount))\n",
    "# creating data frame with values\n",
    "products = pd.DataFrame({})\n",
    "products['Brand']=brand\n",
    "products['Product_Desc']=product_desc\n",
    "products['Price']=price\n",
    "products['Discount']=discount\n",
    "\n",
    "driver.close() # closing chrome driver\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca203f44",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "66f4218a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Woven Design Sneakers</td>\n",
       "      <td>Rs. 13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React MR 3 Running Shoes</td>\n",
       "      <td>Rs. 8920Rs. 10495(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Textured Formal Leather Loafers</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RARE RABBIT</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 7699Rs. 10999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>MANGO</td>\n",
       "      <td>Embellish Mid-Top Heeled Boots</td>\n",
       "      <td>Rs. 7990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Textured Block Pumps</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                         Product_Desc  \\\n",
       "0          ALDO            Men Woven Design Sneakers   \n",
       "1          ALDO            Men Leather Driving Shoes   \n",
       "2      Skechers           Men Max Cushioning Running   \n",
       "3          ALDO                  Men Leather Loafers   \n",
       "4          Nike       Women React MR 3 Running Shoes   \n",
       "..          ...                                  ...   \n",
       "95     DAVINCHI  Men Textured Formal Leather Loafers   \n",
       "96  RARE RABBIT         Men Textured Leather Loafers   \n",
       "97        MANGO       Embellish Mid-Top Heeled Boots   \n",
       "98    J.FONTINI           Men Leather Formal Loafers   \n",
       "99         ALDO                 Textured Block Pumps   \n",
       "\n",
       "                         Price  \n",
       "0                    Rs. 13999  \n",
       "1                    Rs. 12999  \n",
       "2    Rs. 7649Rs. 8999(15% OFF)  \n",
       "3                    Rs. 12999  \n",
       "4   Rs. 8920Rs. 10495(15% OFF)  \n",
       "..                         ...  \n",
       "95                    Rs. 8990  \n",
       "96  Rs. 7699Rs. 10999(30% OFF)  \n",
       "97                    Rs. 7990  \n",
       "98                    Rs. 7490  \n",
       "99                    Rs. 7999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening website on automated chrome window\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "time.sleep(3) # Sleep for 3 seconds to open a page\n",
    "\n",
    "#finding black color checkbox element\n",
    "color_btn=driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label')\n",
    "color_btn.click()\n",
    "time.sleep(2) # Sleep for 2 seconds to open a page\n",
    "\n",
    "#finding price tag checkbox element\n",
    "price_btn=driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "price_btn.click()\n",
    "time.sleep(2) # Sleep for 2 seconds to open a page\n",
    "\n",
    "# finding next button to go to next page\n",
    "next_btn=driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]')\n",
    "\n",
    "# list arrays to capture values\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "\n",
    "#loop for next 3 pages to capture 100 records\n",
    "for i in range(0,2):\n",
    "    brand_tags=driver.find_elements_by_class_name(\"product-brand\")\n",
    "    product_desc_tags=driver.find_elements_by_class_name(\"product-product\")\n",
    "    price_tag=driver.find_elements_by_class_name(\"product-price\")   \n",
    "    for j in range(0,50):\n",
    "        brand.append(brand_tags[j].text)\n",
    "        product_desc.append(product_desc_tags[j].text)\n",
    "        price.append(price_tag[j].text)\n",
    "    if i<=0:\n",
    "        next_btn.click()\n",
    "    else:\n",
    "        time.sleep(2) # putting time sleep for 2 seconds, sometimes page takes time to load\n",
    "        next_button_from_second_page=driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[13]')\n",
    "        next_button_from_second_page.click()\n",
    "    time.sleep(5) \n",
    "\n",
    "\n",
    "#print('Brand Length: ',len(brand),'Desc Length:',len(product_desc),'Price Length:',len(price))\n",
    "# creating data frame with values\n",
    "products = pd.DataFrame({})\n",
    "products['Brand']=brand\n",
    "products['Product_Desc']=product_desc\n",
    "products['Price']=price\n",
    "\n",
    "driver.close() # closing chrome driver\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2d78e",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "83f59852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Predator Helios 300 11th Gen Intel Core i...</td>\n",
       "      <td>1,69,990</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion 11th Gen Intel Core i7 Processor 1...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>86,990</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>57,490</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...</td>\n",
       "      <td>86,990</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 Ev...</td>\n",
       "      <td>79,990</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LG Gram Intel Evo 11th Gen Core i7 17 inches U...</td>\n",
       "      <td>93,999</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LG Gram 16 inches Intel Evo 11th Gen Core i7 U...</td>\n",
       "      <td>1,01,112</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>85,890</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price Rating\n",
       "0  Acer Predator Helios 300 11th Gen Intel Core i...  1,69,990    5.0\n",
       "1  HP Pavilion 11th Gen Intel Core i7 Processor 1...    89,990    4.3\n",
       "2  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...    89,990    4.6\n",
       "3  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    86,990    4.5\n",
       "4  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...    57,490    4.5\n",
       "5  HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...    86,990    4.5\n",
       "6  Samsung Galaxy Book2 Intel 12th Gen core i7 Ev...    79,990      -\n",
       "7  LG Gram Intel Evo 11th Gen Core i7 17 inches U...    93,999    4.5\n",
       "8  LG Gram 16 inches Intel Evo 11th Gen Core i7 U...  1,01,112    4.3\n",
       "9  HP Pavilion x360 11th Gen Intel Core i7 14 inc...    85,890    4.0"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening website on automated chrome window\n",
    "driver.get('https://www.amazon.in/')\n",
    "time.sleep(3) # Sleep for 3 seconds to open a page\n",
    "\n",
    "# find search bar element and enter keyword\n",
    "search_input=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search_input.send_keys('Laptop')\n",
    "\n",
    "# find search button to click\n",
    "search_input=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_input.submit()\n",
    "\n",
    "time.sleep(3) # Sleep for 3 seconds to open a page\n",
    "\n",
    "#finding CPU type checkbox for “Intel Core i7\" value\n",
    "cpu_chk1=driver.find_element_by_xpath(\"//li[@aria-label='Intel Core i7']/span/a\")\n",
    "#/html/body/div[2]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[13]/span/a/div/label/i\n",
    "cpu_chk1.click()\n",
    "time.sleep(2) # Sleep for 2 seconds to open a page\n",
    "\n",
    "\n",
    "\n",
    "# list arrays to capture values\n",
    "title=[]\n",
    "rating=[]\n",
    "price=[]\n",
    "\n",
    "title_tags=driver.find_elements_by_class_name(\"s-line-clamp-2\") # the elements to fetch the product names\n",
    "price_tags=driver.find_elements_by_class_name(\"a-price-whole\")   # the elements to fetch the product price\n",
    "for j in range(0,10):\n",
    "    title.append(title_tags[j].text)\n",
    "    price.append(price_tags[j].text)\n",
    "    try:\n",
    "        rating_element = driver.find_element_by_xpath(\"//span[contains(text(),'\"+title[j][0:25]+\"')]/../../../../div[2]/div/span\") \n",
    "        rating.append(rating_element.get_attribute('aria-label').replace(' out of 5 stars',''))\n",
    "    except:\n",
    "        rating.append('-')\n",
    "#title\n",
    "\n",
    "#print('Brand Length: ',len(brand),'Desc Length:',len(product_desc),'Price Length:',len(price))\n",
    "# creating data frame with values\n",
    "products = pd.DataFrame({})\n",
    "products['Title']=title\n",
    "products['Price']=price\n",
    "products['Rating']=rating\n",
    "\n",
    "driver.close() # closing chrome driver\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bcc71c",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ef321b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Rating</th>\n",
       "      <th># of days ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tech Mahindra Ltd</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1mon ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1mon ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bristlecone India Limited</td>\n",
       "      <td>3.8</td>\n",
       "      <td>12d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zyoin</td>\n",
       "      <td>4.1</td>\n",
       "      <td>16d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Newgen Software Technologies Ltd.</td>\n",
       "      <td>3.5</td>\n",
       "      <td>18d ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Company Rating # of days ago\n",
       "0                     GENPACT India Private Limited    4.0       12d ago\n",
       "1                  EXL Services.com ( I ) Pvt. Ltd.    3.9        5d ago\n",
       "2                     GENPACT India Private Limited    4.0       17d ago\n",
       "3  TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED    3.9        3d ago\n",
       "4                                 Tech Mahindra Ltd    3.7      1mon ago\n",
       "5                     GENPACT India Private Limited    4.0      1mon ago\n",
       "6                         Bristlecone India Limited    3.8       12d ago\n",
       "7                                             Zyoin    4.1       16d ago\n",
       "8                Ashkom Media India Private Limited    3.7        3d ago\n",
       "9                 Newgen Software Technologies Ltd.    3.5       18d ago"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "time.sleep(2)\n",
    "\n",
    "#find job link to click\n",
    "job_link=driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "\n",
    "job_link.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# finding elements for job search bar\n",
    "search_field_designation=driver.find_element_by_class_name('tt-input')\n",
    "search_field_designation.send_keys('Data Scientist')\n",
    "\n",
    "# finding search button elements for job search bar\n",
    "search_btn=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span')\n",
    "search_btn.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# finding element for location dropdown\n",
    "location_dropdown=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i')\n",
    "location_dropdown.click()\n",
    "\n",
    "# finding element for location\n",
    "location_ele=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "location_ele.send_keys('Noida')\n",
    "time.sleep(2)\n",
    "\n",
    "# finding element for noida location radio button\n",
    "location_radio=driver.find_element_by_id('location_Noida')\n",
    "location_radio.click()\n",
    "\n",
    "time.sleep(2) # Sleep for 2 seconds to open a page\n",
    "\n",
    "#extracting all the tags having ,company names,location adn experience\n",
    "company_tags=driver.find_elements_by_xpath(\"//div[@class='info']/div/p\")\n",
    "company_ratings=driver.find_elements_by_xpath(\"//div[@class='info']/div/div/a/span\")\n",
    "company_daysago=driver.find_elements_by_xpath(\"//div[@class='other-info']/span[1]\")\n",
    "#len(company_tags)\n",
    "#len(company_ratings)\n",
    "#len(company_daysago)\n",
    "\n",
    "#creating empty list to capture reults\n",
    "company=[]\n",
    "rating=[]\n",
    "daysago=[]\n",
    "\n",
    "# Fetching data from tags and appending in list elements\n",
    "for i in range(0,10):\n",
    "    company.append(company_tags[i].text)\n",
    "    rating.append(company_ratings[i].text)\n",
    "    daysago.append(company_daysago[i].text)\n",
    "\n",
    "\n",
    "#Create data frame\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Company']=company\n",
    "jobs['Rating']=rating\n",
    "jobs['# of days ago']=daysago\n",
    "\n",
    "driver.close()\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    ". First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "357f0039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Total_Salaries</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Avg_CTC</th>\n",
       "      <th>Min_CTC</th>\n",
       "      <th>Max_CTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>3 yrs exp</td>\n",
       "      <td>₹ 29.7L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 32 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 18.9L</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>2 yrs exp</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 81 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 46 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 53 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company        Total_Salaries   Experience  Avg_CTC  \\\n",
       "0                   Walmart  based on 11 salaries    3 yrs exp  ₹ 29.7L   \n",
       "1                  Ab Inbev  based on 32 salaries  3-4 yrs exp  ₹ 20.5L   \n",
       "2              Reliance Jio  based on 10 salaries    4 yrs exp  ₹ 18.9L   \n",
       "3                        ZS  based on 15 salaries    2 yrs exp  ₹ 15.9L   \n",
       "4                     Optum  based on 27 salaries  3-4 yrs exp  ₹ 15.2L   \n",
       "5         Fractal Analytics  based on 81 salaries  2-4 yrs exp  ₹ 15.2L   \n",
       "6           Tiger Analytics  based on 46 salaries  2-4 yrs exp  ₹ 14.8L   \n",
       "7              UnitedHealth  based on 53 salaries  2-4 yrs exp  ₹ 14.0L   \n",
       "8                   Verizon  based on 14 salaries    4 yrs exp  ₹ 12.7L   \n",
       "9  Ganit Business Solutions  based on 13 salaries    4 yrs exp  ₹ 12.4L   \n",
       "\n",
       "   Min_CTC  Max_CTC  \n",
       "0  ₹ 25.0L  ₹ 35.0L  \n",
       "1  ₹ 15.0L  ₹ 25.5L  \n",
       "2   ₹ 5.6L  ₹ 26.2L  \n",
       "3   ₹ 9.8L  ₹ 20.0L  \n",
       "4  ₹ 11.0L  ₹ 22.0L  \n",
       "5   ₹ 9.5L  ₹ 22.0L  \n",
       "6   ₹ 9.0L  ₹ 20.0L  \n",
       "7   ₹ 8.3L  ₹ 20.5L  \n",
       "8  ₹ 10.0L  ₹ 21.0L  \n",
       "9   ₹ 8.5L  ₹ 15.0L  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with driver\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#opening website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "time.sleep(2)\n",
    "\n",
    "#find salary link to click\n",
    "salary_link=driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "salary_link.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# finding elements for job profile search bar\n",
    "search_field_designation=driver.find_element_by_id('jobProfileSearchbox')\n",
    "search_field_designation.send_keys('Data Scientist')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#finding 'Data Scientists' quick search element\n",
    "reslt_designations=driver.find_elements_by_class_name(\"tt-selectable\")\n",
    "reslt_designations[0].text\n",
    "for val in reslt_designations:\n",
    "    if val.text=='Data Scientist':\n",
    "        val.click()\n",
    "\n",
    "time.sleep(2)\n",
    "company_tags=driver.find_elements_by_xpath(\"//div[@class='name']/a\")\n",
    "total_salaries_tags=driver.find_elements_by_xpath(\"//div[@class='name']/span\")\n",
    "experience_req_tags=driver.find_elements_by_xpath(\"//div[@class='company-info']/div[2]\")\n",
    "avg_ctc_tags=driver.find_elements_by_xpath(\"//div[@class='results-body']//p[@class='averageCtc']\")\n",
    "min_ctc_tags=driver.find_elements_by_xpath(\"//div[@class='results-body']//div[@class='salary-values']/div[1]\")\n",
    "max_ctc_tags=driver.find_elements_by_xpath(\"//div[@class='results-body']//div[@class='salary-values']/div[2]\")\n",
    "\n",
    "#print(len(company_tags),'-',len(total_salaries_tags),'-',len(experience_req_tags),'-',len(avg_ctc_tags),'-',len(min_ctc_tags),'-',len(max_ctc_tags))\n",
    "# creating empty lists\n",
    "company=[]\n",
    "total_salaries=[]\n",
    "experience_req=[]\n",
    "avg_ctc=[]\n",
    "min_ctc=[]\n",
    "max_ctc=[]\n",
    "\n",
    "# Fetching data from tags and appending in list elements\n",
    "for i in range(0,10):\n",
    "    company.append(company_tags[i].text)\n",
    "    total_salaries.append(total_salaries_tags[i].text.replace(\"(\",\"\").replace(\")\",\"\"))\n",
    "    experience_req.append(experience_req_tags[i].text.replace(\"Data Scientist\\n . \\n\",\"\"))\n",
    "    avg_ctc.append(avg_ctc_tags[i].text)\n",
    "    min_ctc.append(min_ctc_tags[i].text)\n",
    "    max_ctc.append(max_ctc_tags[i].text)\n",
    "\n",
    "\n",
    "#Create data frame\n",
    "salaries=pd.DataFrame({})\n",
    "salaries['Company']=company\n",
    "salaries['Total_Salaries']=total_salaries\n",
    "salaries['Experience']=experience_req\n",
    "salaries['Avg_CTC']=avg_ctc\n",
    "salaries['Min_CTC']=min_ctc\n",
    "salaries['Max_CTC']=max_ctc\n",
    "\n",
    "#driver.close()\n",
    "\n",
    "salaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38abaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
